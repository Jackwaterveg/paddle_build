{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1478fda",
   "metadata": {},
   "source": [
    "## 全局变量设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5f166ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "iteration = 1\n",
    "workspace_dir = \"/home/HYX/workspace\"\n",
    "use_ctc_loss = False\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68052e90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/home/HYX/workspace/DeepSpeech'\n",
      "/home/huangyuxin/workspace/paddle_build/notebook\n"
     ]
    }
   ],
   "source": [
    "%cd /home/HYX/workspace/DeepSpeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5f89f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature_dir= os.path.join(workspace_dir, \"DeepSpeech/compare/workspace_aishell_asr/feature_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba66a488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-02-28 06:57:31--  https://paddlespeech.bj.bcebos.com/model_alignment/s2t/conformer/check_conformer_layernorm_aishell_paddlespeech.tgz\n",
      "Connecting to 172.19.57.45:3128... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 180879331 (172M) [application/x-gzip]\n",
      "Saving to: ‘./compare/check_conformer_layernorm_aishell_paddlespeech.tgz’\n",
      "\n",
      "_conformer_layernor   0%[                    ] 250.84K  51.8KB/s    eta 57m 59s^C\n",
      "workspace_aishell_asr/\n",
      "workspace_aishell_asr/conf/\n",
      "workspace_aishell_asr/conf/conformer.yaml\n",
      "workspace_aishell_asr/checkpoints/\n",
      "workspace_aishell_asr/checkpoints/init_whole.pdparams\n",
      "\n",
      "gzip: stdin: unexpected end of file\n",
      "tar: Unexpected EOF in archive\n",
      "tar: Unexpected EOF in archive\n",
      "tar: Error is not recoverable: exiting now\n"
     ]
    }
   ],
   "source": [
    "!test -d compare/workspace_aishell_asr || wget -nc https://paddlespeech.bj.bcebos.com/model_alignment/s2t/conformer/check_conformer_layernorm_aishell_paddlespeech.tgz -P ./compare\n",
    "!test -d compare/workspace_aishell_asr || tar xzvf compare/check_conformer_layernorm_aishell_paddlespeech.tgz -C ./compare\n",
    "!mkdir -p ./compare/workspace_aishell_asr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64c691bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-02-28 06:57:40--  https://paddlespeech.bj.bcebos.com/datasets/single_wav/zh/demo_01_03.wav\n",
      "Connecting to 172.19.57.45:3128... connected.\n",
      "Proxy request sent, awaiting response... ^C\n"
     ]
    }
   ],
   "source": [
    "# 获取用于预测的音频文件\n",
    "!test -f ./data/demo_01_03.wav || wget -nc https://paddlespeech.bj.bcebos.com/datasets/single_wav/zh/demo_01_03.wav -P ./data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85a5b79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: Can not import avx core while this file exists: /root/miniconda3/lib/python3.7/site-packages/paddle/fluid/core_avx.so\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-6-df122f080af1>\", line 2, in <module>\n",
      "    import paddle\n",
      "  File \"/root/miniconda3/lib/python3.7/site-packages/paddle/__init__.py\", line 25, in <module>\n",
      "    from .fluid import monkey_patch_variable\n",
      "  File \"/root/miniconda3/lib/python3.7/site-packages/paddle/fluid/__init__.py\", line 36, in <module>\n",
      "    from . import framework\n",
      "  File \"/root/miniconda3/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 37, in <module>\n",
      "    from . import core\n",
      "  File \"/root/miniconda3/lib/python3.7/site-packages/paddle/fluid/core.py\", line 294, in <module>\n",
      "    raise e\n",
      "  File \"/root/miniconda3/lib/python3.7/site-packages/paddle/fluid/core.py\", line 256, in <module>\n",
      "    from .core_avx import *\n",
      "ImportError: KeyboardInterrupt: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2064, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ImportError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/root/miniconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/root/miniconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/root/miniconda3/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/root/miniconda3/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/root/miniconda3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/root/miniconda3/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/root/miniconda3/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/root/miniconda3/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/root/miniconda3/lib/python3.7/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-df122f080af1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msoundfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/paddle/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbatch\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfluid\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmonkey_patch_variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfluid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdygraph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmonkey_patch_math_varbase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/paddle/fluid/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# import all class inside framework into fluid module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mframework\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/paddle/fluid/framework.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munique_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/paddle/fluid/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    293\u001b[0m                 current_path + os.sep + 'core_avx.' + core_suffix + '\\n')\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/paddle/fluid/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore_avx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore_avx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__doc__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__file__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__package__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: KeyboardInterrupt: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2063\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2064\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2065\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ImportError' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2065\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2066\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2067\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2069\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1368\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             )\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1125\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "import soundfile\n",
    "import paddle\n",
    "import warnings\n",
    "import numpy as np\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from yacs.config import CfgNode\n",
    "from paddlespeech.s2t.transform.spectrogram import LogMelSpectrogramKaldi\n",
    "from paddlespeech.s2t.transform.cmvn import GlobalCMVN\n",
    "from paddlespeech.s2t.frontend.featurizer.text_featurizer import TextFeaturizer\n",
    "from paddlespeech.s2t.models.u2 import U2Model\n",
    "from paddlespeech.s2t.training.optimizer import OptimizerFactory\n",
    "from paddlespeech.s2t.training.scheduler import LRSchedulerFactory\n",
    "from matplotlib import pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bbc52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"compare/workspace_aishell_asr/conf/conformer.yaml\" \n",
    "decode_config_path = \"compare/workspace_aishell_asr/conf/tuning/decode.yaml\"\n",
    "checkpoint_path = os.path.join(\"compare/workspace_aishell_asr/checkpoints/init_whole.pdparams\")\n",
    "#checkpoint_path = os.path.join(workspace_dir, \"wenet/examples/aishell/s0/exp/conformer_noLayernorm/init_no_layernorm2.pdparams\")\n",
    "\n",
    "audio_file = \"compare/workspace_aishell_asr/data/demo_01_03.wav\"\n",
    "text_data = \"我认为跑步最重要的就是给我带来了身体健康\"\n",
    "\n",
    "# 读取 conf 文件并结构化\n",
    "conformer_config = CfgNode(new_allowed=True)\n",
    "conformer_config.merge_from_file(config_path)\n",
    "decode_config = CfgNode(new_allowed=True)\n",
    "decode_config.merge_from_file(decode_config_path)\n",
    "conformer_config.decode = decode_config\n",
    "conformer_config.decode.decoding_method = decoding_method\n",
    "conformer_config.vocab_filepath = os.path.join(workspace_dir, \"DeepSpeech/compare/workspace_aishell_asr/data/lang_char/vocab.txt\")\n",
    "\n",
    "print(conformer_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8d4d64",
   "metadata": {},
   "source": [
    "## 特征处理工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61005c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建 logmel 特征\n",
    "logmel_kaldi= LogMelSpectrogramKaldi(\n",
    "            fs= 16000,\n",
    "            n_mels= 80,\n",
    "            n_shift= 160,\n",
    "            win_length= 400,\n",
    "            dither= True)\n",
    "\n",
    "# 特征减均值除以方差\n",
    "cmvn = GlobalCMVN(\n",
    "    cmvn_path=\"compare/workspace_aishell_asr/data/mean_std.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96cddb1",
   "metadata": {},
   "source": [
    "## 处理特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28349339",
   "metadata": {},
   "outputs": [],
   "source": [
    "array, _ = soundfile.read(audio_file, dtype=\"int16\")\n",
    "array = logmel_kaldi(array, train=False)\n",
    "audio_feature_i = cmvn(array)\n",
    "audio_len_i = audio_feature_i.shape[0]\n",
    "\n",
    "text_featurizer = TextFeaturizer(unit_type='char',\n",
    "                            vocab=conformer_config.vocab_filepath)\n",
    "text_feat_i = text_featurizer.featurize(text_data)\n",
    "text_len_i = len(text_feat_i)\n",
    "\n",
    "audio_len = paddle.to_tensor(audio_len_i)\n",
    "audio_feature = paddle.to_tensor(audio_feature_i, dtype='float32')\n",
    "audio_feature = paddle.unsqueeze(audio_feature, axis=0)\n",
    "\n",
    "text_feat = paddle.to_tensor([text_feat_i])\n",
    "text_len = paddle.to_tensor([text_feat.shape[1]])\n",
    "\n",
    "np.save(os.path.join(Feature_dir, \"audio_feature_i.npy\"), audio_feature_i)\n",
    "np.save(os.path.join(Feature_dir, \"audio_len_i.npy\"), audio_len_i)\n",
    "np.save(os.path.join(Feature_dir, \"text_feat_i.npy\"), text_feat_i)\n",
    "np.save(os.path.join(Feature_dir, \"text_len_i.npy\"), text_len_i)\n",
    "\n",
    "print (\"audio_feature\", audio_feature)\n",
    "print (\"audio_len\", audio_len)\n",
    "print (\"text_feat\", text_feat)\n",
    "print (\"text_len\", text_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3452fce",
   "metadata": {},
   "source": [
    "## 构建Conformer模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e36ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conf = conformer_config\n",
    "# input_dim 存储的是特征的纬度\n",
    "model_conf.input_dim = 80\n",
    "# output_dim 存储的字表的长度\n",
    "model_conf.output_dim = 4233 \n",
    "\n",
    "# model_conf.model_conf.ctc_weight=0.0\n",
    "print (\"model_conf\", model_conf)\n",
    "model = U2Model.from_config(model_conf)\n",
    "for name, value in model.named_parameters():\n",
    "    print (name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1629bda",
   "metadata": {},
   "source": [
    "## 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9da7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = paddle.load(checkpoint_path)\n",
    "model.set_state_dict(model_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd16d4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = conformer_config\n",
    "optim_type = train_config.optim\n",
    "optim_conf = train_config.optim_conf\n",
    "\n",
    "scheduler_type = train_config.scheduler\n",
    "scheduler_conf = train_config.scheduler_conf\n",
    "\n",
    "\n",
    "scheduler_args = {\n",
    "    \"learning_rate\": optim_conf.lr,\n",
    "    \"verbose\": False,\n",
    "    \"warmup_steps\": scheduler_conf.warmup_steps,\n",
    "    \"gamma\": scheduler_conf.lr_decay,\n",
    "    \"d_model\": model_conf.encoder_conf.output_size,\n",
    "}\n",
    "lr_scheduler = LRSchedulerFactory.from_args(scheduler_type,\n",
    "                                            scheduler_args)\n",
    "\n",
    "def optimizer_args(\n",
    "                config,\n",
    "                parameters,\n",
    "                lr_scheduler=None, ):\n",
    "    train_config = config\n",
    "    optim_type = train_config.optim\n",
    "    optim_conf = train_config.optim_conf\n",
    "    scheduler_type = train_config.scheduler\n",
    "    scheduler_conf = train_config.scheduler_conf\n",
    "    return {\n",
    "        \"grad_clip\": train_config.global_grad_clip,\n",
    "        \"weight_decay\": optim_conf.weight_decay,\n",
    "        \"learning_rate\": lr_scheduler\n",
    "        if lr_scheduler else optim_conf.lr,\n",
    "        \"parameters\": parameters,\n",
    "        \"epsilon\": 1e-9 if optim_type == 'noam' else None,\n",
    "        \"beta1\": 0.9 if optim_type == 'noam' else None,\n",
    "        \"beat2\": 0.98 if optim_type == 'noam' else None,\n",
    "    }\n",
    "\n",
    "optimzer_args = optimizer_args(conformer_config, model.parameters(), lr_scheduler)\n",
    "optimizer = OptimizerFactory.from_args(optim_type, optimzer_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7170d19",
   "metadata": {},
   "source": [
    "## 进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeda883",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (iteration):\n",
    "    paddle.set_device('gpu')\n",
    "    model.eval()\n",
    "    # encoder_out_model, encoder_mask_model = model._forward_encoder(audio_feature, audio_len)\n",
    "\n",
    "    # encoder_out_paddle = encoder_out_model.numpy()\n",
    "    # print (\"encoder_out_model\", encoder_out_model)\n",
    "    # np.save(\"paddle_encoder_out\", encoder_out.numpy())\n",
    "\n",
    "    # print (\"encoder_out\", encoder_out)\n",
    "    # print (\"encoder_mask\", encoder_mask)\n",
    "\n",
    "    # encoder_out_np = np.load(os.path.join(workspace_dir, \"DeepSpeech/compare/wenet/encoder_out.npy\")\n",
    "    # encoder_mask_np = np.load(os.path.join(workspace_dir, \"DeepSpeech/compare/wenet/encoder_mask.npy\")\n",
    "    # encoder_out = paddle.to_tensor(encoder_out_np)\n",
    "    # encoder_mask = paddle.to_tensor(encoder_mask_np)\n",
    "\n",
    "\n",
    "    # print (\"encoder_out_model - encoder_out\", encoder_out_model - encoder_out)\n",
    "\n",
    "    # encoder_out = None\n",
    "    # encoder_mask = None\n",
    "    print (\"lr\", optimizer.get_lr())\n",
    "    loss, attention_loss, ctc_loss = model(audio_feature, audio_len, text_feat,\n",
    "                                                        text_len)\n",
    "\n",
    "    print (\"loss\", loss)\n",
    "    print (\"attention_loss\", attention_loss)\n",
    "    print (\"ctc_loss\", ctc_loss)\n",
    "    if use_ctc_loss == True:\n",
    "        ctc_loss.backward()\n",
    "    else:\n",
    "        attention_loss.backward()\n",
    "    \n",
    "\n",
    "    paddle_grad_dict = {}\n",
    "    count = 0\n",
    "    for n, p in model.named_parameters():\n",
    "        count += 1\n",
    "        msg = f\"param grad: {n}: shape: {p.shape} grad: {p.grad}\"\n",
    "        #msg = f\"param grad: {n}: shape: {p.shape}\"\n",
    "        print (n)\n",
    "        if p.grad is not None:\n",
    "            paddle_grad_dict[n] = p.grad.numpy()\n",
    "        else:\n",
    "            pass\n",
    "        try:\n",
    "            # 查看一下其中几个受关注的参数的 grad\n",
    "            if (n == \"decoder.decoders.5.norm3.bias\"):\n",
    "                print (msg)\n",
    "                print (p.grad.numpy())\n",
    "            \n",
    "            if (n == \"ctc.ctc_lo.bias\"): \n",
    "                print(msg)\n",
    "                print (p.grad.numpy())\n",
    "                np.save(\"paddle_ctc_bias.npy\", p.grad.numpy())\n",
    "        except:\n",
    "            pass\n",
    "    print (count)\n",
    "    \n",
    "    optimizer.step()\n",
    "    optimizer.clear_grad()\n",
    "    lr_scheduler.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbc63bc",
   "metadata": {},
   "source": [
    "## wenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9dc0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/HYX/workspace/wenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae255caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p examples/aishell/s0/exp/conformer_layernorm\n",
    "!wget https://paddlespeech.bj.bcebos.com/model_alignment/s2t/conformer/wenet_aishell_s0_layernorm_init.tgz\n",
    "!tar xzvf wenet_aishell_s0_layernorm_init.tgz -C examples/aishell/s0/exp/conformer_layernorm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efb6187",
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature_dir=os.path.join(workspace_dir, \"DeepSpeech/compare/workspace_aishell_asr/feature_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdbf7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!test -f 20211025_conformer_exp.tar.gz || wget https://wenet-1256283475.cos.ap-shanghai.myqcloud.com/models/wenetspeech/20211025_conformer_exp.tar.gz\n",
    "!tar xzvf 20211025_conformer_exp.tar.gz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabdc3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wenet.transformer.asr_model import init_asr_model\n",
    "from wenet.utils.checkpoint import load_checkpoint, save_checkpoint\n",
    "from wenet.utils.file_utils import read_symbol_table, read_non_lang_symbols\n",
    "import yaml\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from wenet.utils.executor import Executor\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from wenet.utils.scheduler import WarmupLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51328cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_file=os.path.join(workspace_dir, 'wenet/examples/aishell/s0/exp/conformer_noLayernorm/train.yaml')\n",
    "# checkpoint=os.path.join(workspace_dir, 'wenet/examples/aishell/s0/exp/conformer_noLayernorm/init.pt')\n",
    "# cmvn_file=os.path.join(workspace_dir, 'wenet/examples/aishell/s0/exp/conformer_noLayernorm/global_cmvn')\n",
    "# symbol_table=os.path.join(workspace_dir, 'wenet/examples/aishell/s0/exp/conformer_noLayernorm/lang_char.txt')\n",
    "\n",
    "\n",
    "config_file=os.path.join(workspace_dir, 'wenet/examples/aishell/s0/exp/conformer_layernorm/train.yaml')\n",
    "checkpoint=os.path.join(workspace_dir, 'wenet/examples/aishell/s0/exp/conformer_layernorm/init.pt')\n",
    "cmvn_file=os.path.join(workspace_dir, 'wenet/examples/aishell/s0/exp/conformer_layernorm/global_cmvn')\n",
    "symbol_table=os.path.join(workspace_dir, 'wenet/examples/aishell/s0/exp/conformer_layernorm/lang_char.txt')\n",
    "\n",
    "symbol_table = read_symbol_table(symbol_table)\n",
    "vocab_size = len(symbol_table)\n",
    "with open(config_file, 'r') as fin:\n",
    "    configs = yaml.load(fin, Loader=yaml.FullLoader)\n",
    "train_conf = configs['dataset_conf']\n",
    "input_dim = configs['dataset_conf']['fbank_conf']['num_mel_bins']\n",
    "configs['input_dim'] = input_dim\n",
    "configs['output_dim'] = vocab_size\n",
    "configs['cmvn_file'] = cmvn_file\n",
    "configs['is_json_cmvn'] = True\n",
    "\n",
    "print (configs)\n",
    "model = init_asr_model(configs)\n",
    "for name, value in model.named_parameters():\n",
    "    print (name)\n",
    "infos = load_checkpoint(model, checkpoint)\n",
    "print (model)\n",
    "print (infos)\n",
    "# hack\n",
    "model.encoder.global_cmvn=None\n",
    "\n",
    "print (model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef62da2",
   "metadata": {},
   "source": [
    "## 生成特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0201aa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_feature_i = np.load(os.path.join(Feature_dir, \"audio_feature_i.npy\"))\n",
    "audio_len_i = np.load(os.path.join(Feature_dir, \"audio_len_i.npy\"))\n",
    "text_feat_i = np.load(os.path.join(Feature_dir, \"text_feat_i.npy\"))\n",
    "text_len_i = np.load(os.path.join(Feature_dir, \"text_len_i.npy\"))\n",
    "print (type(audio_len_i))\n",
    "\n",
    "device = \"cuda\"\n",
    "feats = torch.tensor([audio_feature_i], dtype=torch.float32, device = device)\n",
    "feats_lengths = torch.tensor([int(audio_len_i)], device = device )\n",
    "\n",
    "target = torch.tensor([text_feat_i], device = device)\n",
    "target_lengths = torch.tensor([int(text_len_i)], device = device)\n",
    "\n",
    "print (feats)\n",
    "print (feats_lengths)\n",
    "print (target)\n",
    "print (target_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64e1b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "step = -1\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), **configs['optim_conf'])\n",
    "scheduler = WarmupLR(optimizer, **configs['scheduler_conf'])\n",
    "\n",
    "\n",
    "scheduler.set_step(step)\n",
    "scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b02fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _ in range(10):\n",
    "#     lr = optimizer.param_groups[0]['lr']\n",
    "#     print (\"lr\", lr)\n",
    "#     optimizer.step()\n",
    "#     optimizer.zero_grad()\n",
    "#     scheduler.step()\n",
    "\"\"\"\n",
    "lr 8e-08\n",
    "lr 8e-08\n",
    "lr 1.6e-07\n",
    "lr 2.4e-07\n",
    "lr 3.2e-07\n",
    "lr 4e-07\n",
    "lr 4.8e-07\n",
    "lr 5.6e-07\n",
    "lr 6.4e-07\n",
    "lr 7.2e-07\n",
    "\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c98837",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (iteration):    \n",
    "    model.eval()\n",
    "\n",
    "#     encoder_out, encoder_mask = model._forward_encoder(feats, feats_lengths)\n",
    "\n",
    "#     encoder_out_torch = encoder_out.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "    loss, loss_att, loss_ctc = model(\n",
    "                                feats, feats_lengths, target, target_lengths)\n",
    "    print (\"loss\", loss.cpu().detach().numpy())\n",
    "    print (\"loss_att\", loss_att.cpu().detach().numpy())\n",
    "    print (\"loss_ctc\", loss_ctc.cpu().detach().numpy())\n",
    "    if use_ctc_loss == True:\n",
    "        loss_ctc.backward()\n",
    "    else:\n",
    "        loss_att.backward()\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    print (\"lr\", lr)\n",
    "    \n",
    "    wenet_grad_dict = {}\n",
    "    count = 0\n",
    "\n",
    "    print (\"The following are grads:\")\n",
    "    for name,item in model.named_parameters():\n",
    "        count += 1\n",
    "\n",
    "        #print (item.grad)\n",
    "        if item.grad != None:\n",
    "            print (name)\n",
    "            wenet_grad_dict[name] = item.grad.cpu().numpy()\n",
    "        try:\n",
    "            if (name == \"decoder.decoders.5.norm3.bias\"):\n",
    "                print (name, item.grad.cpu().numpy())\n",
    "            if name == \"ctc.ctc_lo.bias\":\n",
    "                print (name, item.grad.cpu().numpy())\n",
    "        except:\n",
    "            pass\n",
    "    print (count)  \n",
    "    \n",
    "    # 更新模型\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    scheduler.step()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475431b7",
   "metadata": {},
   "source": [
    "\n",
    "# 转换wenet（torch）的grad 为paddle格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b4c8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_to_paddle(model_state_dict): \n",
    "    paddle_state_dict = {}\n",
    "    for n, p in model_state_dict.items():\n",
    "        print(f'-> name: {n} dim: {p.ndim}')\n",
    "        \n",
    "        # change norm.mean and norm variance\n",
    "        name_change=True\n",
    "        if 'norm.running_mean' in n:\n",
    "            new_n = n.replace('norm.running_', 'norm._')\n",
    "        elif 'norm.running_var' in n:\n",
    "            new_n = n.replace('norm.running_var', 'norm._variance')\n",
    "        else:\n",
    "            name_change=False\n",
    "            new_n = n\n",
    "        if name_change:\n",
    "            print(f\"\\t norm mean/var: {n} -> {new_n}\")\n",
    "\n",
    "        #p = p.cpu().detach().numpy()\n",
    "        \n",
    "        # weight which is rank 2, transpose it\n",
    "        if n.endswith('weight') and p.ndim == 2:\n",
    "            new_p = p.T\n",
    "            print(f\"\\t liner transpose: {n}: {p.shape} -> {new_p.shape}\")\n",
    "        else:\n",
    "            new_p = p\n",
    "        \n",
    "        # text embedding layer\n",
    "        if 'decoder.embed.0.weight' in n:\n",
    "            new_p = p\n",
    "\n",
    "        if 'global_cmvn.mean' in n:\n",
    "            print(\"\\t cmvn:\", p, p.dtype)\n",
    "        if 'global_cmvn.istd' in n:\n",
    "            print(\"\\t istd:\", p, p.dtype)\n",
    "\n",
    "        paddle_state_dict[new_n] = new_p\n",
    "    return paddle_state_dict\n",
    "wenet_to_paddle_grad_dict = torch_to_paddle(wenet_grad_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678d0024",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in paddle_grad_dict:\n",
    "    torch_grad = wenet_to_paddle_grad_dict[key]\n",
    "    paddle_grad = paddle_grad_dict[key]\n",
    "    \n",
    "    res =np.allclose(torch_grad, paddle_grad, rtol=1e-5, atol=1e-6)\n",
    "    if (res == False):\n",
    "        print (key)\n",
    "#         print (\"torch_grad\", torch_grad)\n",
    "#         print (\"paddle_grad\", paddle_grad)\n",
    "        print (res)\n",
    "        print (key, \"max_grad_diff\", np.max(abs(torch_grad - paddle_grad)))\n",
    "        print (\"mean grad diff\", np.mean(abs(torch_grad - paddle_grad)))\n",
    "        print (\"mean\", np.mean(abs(torch_grad)))\n",
    "        print (\"has false\")\n",
    "        \n",
    "#     if (key == \"encoder.encoders.0.conv_module.pointwise_conv1.weight\"):\n",
    "#         print (\"torch_grad\")\n",
    "#         print (torch_grad)\n",
    "#         print (\"paddle_grad\")\n",
    "#         print (paddle_grad)\n",
    "#     if (key == \"ctc.ctc_lo.bias\"):\n",
    "#         print (torch_grad)\n",
    "#         print (paddle_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6413dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e114ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdb03e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
