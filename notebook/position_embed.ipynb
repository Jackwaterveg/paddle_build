{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c4def20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CPUPlace"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import paddle\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "paddle.set_device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29004da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c98c1ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57849ff5",
   "metadata": {},
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "543c30fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPositionalEncoding(paddle.nn.Layer):\n",
    "    def __init__(self,\n",
    "                 d_model: int,\n",
    "                 dropout_rate: float,\n",
    "                 max_len: int=5000,\n",
    "                 reverse: bool=False):\n",
    "        \"\"\"Positional encoding.\n",
    "            PE(pos, 2i)   = sin(pos/(10000^(2i/dmodel)))\n",
    "            PE(pos, 2i+1) = cos(pos/(10000^(2i/dmodel)))\n",
    "        Args:\n",
    "            d_model (int): embedding dim.\n",
    "            dropout_rate (float): dropout rate.\n",
    "            max_len (int, optional): maximum input length. Defaults to 5000.\n",
    "            reverse (bool, optional): Not used. Defaults to False.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.max_len = max_len\n",
    "        self.xscale = math.sqrt(self.d_model)\n",
    "        self.dropout = paddle.nn.Dropout(p=dropout_rate)\n",
    "        self.pe = paddle.zeros([self.max_len, self.d_model])  #[T,D]\n",
    "\n",
    "        position = np.arange(\n",
    "            0, self.max_len, dtype=np.float32).reshape(-1,1)  #[T, 1]\n",
    "        div_term = np.exp(\n",
    "            np.arange(0, self.d_model, 2, dtype=np.float32) *\n",
    "            -(math.log(10000.0) / self.d_model))\n",
    "\n",
    "        self.pe[:, 0::2] = np.sin(position * div_term)\n",
    "        self.pe[:, 1::2] = np.cos(position * div_term)\n",
    "        self.pe = self.pe.unsqueeze(0)  #[1, T, D]\n",
    "\n",
    "    def forward(self, x: paddle.Tensor,\n",
    "                offset: int=0):\n",
    "        \"\"\"Add positional encoding.\n",
    "        Args:\n",
    "            x (paddle.Tensor): Input. Its shape is (batch, time, ...)\n",
    "            offset (int): position offset\n",
    "        Returns:\n",
    "            paddle.Tensor: Encoded tensor. Its shape is (batch, time, ...)\n",
    "            paddle.Tensor: for compatibility to RelPositionalEncoding, (batch=1, time, ...)\n",
    "        \"\"\"\n",
    "        T = x.shape[1]\n",
    "        assert offset + x.shape[1] < self.max_len\n",
    "        pos_emb = self.pe[:, offset:offset + T]\n",
    "        x = x * self.xscale + pos_emb\n",
    "        return x, self.dropout(pos_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac895f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout_rate, max_len=5000, reverse=False):\n",
    "        \"\"\"Construct an PositionalEncoding object.\"\"\"\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.reverse = reverse\n",
    "        self.xscale = math.sqrt(self.d_model)\n",
    "        self.dropout = torch.nn.Dropout(p=dropout_rate)\n",
    "        self.pe = None\n",
    "        self.extend_pe(torch.tensor(0.0).expand(1, max_len))\n",
    "\n",
    "    def extend_pe(self, x):\n",
    "        \"\"\"Reset the positional encodings.\"\"\"\n",
    "        if self.pe is not None:\n",
    "            if self.pe.size(1) >= x.size(1):\n",
    "                if self.pe.dtype != x.dtype or self.pe.device != x.device:\n",
    "                    self.pe = self.pe.to(dtype=x.dtype, device=x.device)\n",
    "                return\n",
    "        pe = torch.zeros(x.size(1), self.d_model)\n",
    "        if self.reverse:\n",
    "            position = torch.arange(\n",
    "                x.size(1) - 1, -1, -1.0, dtype=torch.float32\n",
    "            ).unsqueeze(1)\n",
    "        else:\n",
    "            position = torch.arange(0, x.size(1), dtype=torch.float32).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, self.d_model, 2, dtype=torch.float32)\n",
    "            * -(math.log(10000.0) / self.d_model)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.pe = pe.to(device=x.device, dtype=x.dtype)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"Add positional encoding.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor (batch, time, `*`).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Encoded tensor (batch, time, `*`).\n",
    "\n",
    "        \"\"\"\n",
    "        self.extend_pe(x)\n",
    "        x = x * self.xscale + self.pe[:, : x.size(1)]\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "afc52bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = PPositionalEncoding(512, 0., 5000, False)\n",
    "t = PositionalEncoding(512, 0., 5000, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f76b61b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPositionalEncoding(\n",
      "  (dropout): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
      ")\n",
      "PositionalEncoding(\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(p)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aabe152b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PositionalEncoding(\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.eval()\n",
    "t.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "390d7e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[1, 524, 512], dtype=float32, place=CPUPlace, stop_gradient=True,\n",
      "       [[[ 1.71176422,  0.12073142,  0.97230834, ...,  0.53358287, -0.87280411, -0.32130694],\n",
      "         [ 1.15618110,  1.56292164, -1.16467249, ...,  0.11234190, -0.94012439,  0.37479785],\n",
      "         [-1.26758003,  1.14918125,  0.03674709, ...,  0.98526299,  0.52364922,  0.68854672],\n",
      "         ...,\n",
      "         [-0.49465108, -0.21408804, -1.06921721, ...,  1.38299918,  0.88839310, -0.09368137],\n",
      "         [-1.20485342,  1.27089787,  0.79920202, ...,  0.06341895, -0.07299408, -0.47029728],\n",
      "         [-0.47220495,  0.82722157,  0.66641206, ..., -1.73230171, -1.52152562, -0.45902300]]])\n",
      "tensor([[[ 1.7118,  0.1207,  0.9723,  ...,  0.5336, -0.8728, -0.3213],\n",
      "         [ 1.1562,  1.5629, -1.1647,  ...,  0.1123, -0.9401,  0.3748],\n",
      "         [-1.2676,  1.1492,  0.0367,  ...,  0.9853,  0.5236,  0.6885],\n",
      "         ...,\n",
      "         [-0.4947, -0.2141, -1.0692,  ...,  1.3830,  0.8884, -0.0937],\n",
      "         [-1.2049,  1.2709,  0.7992,  ...,  0.0634, -0.0730, -0.4703],\n",
      "         [-0.4722,  0.8272,  0.6664,  ..., -1.7323, -1.5215, -0.4590]]])\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randn(1, 524, 512).astype(np.float32)\n",
    "px = paddle.to_tensor(x)\n",
    "tx = torch.as_tensor(x)\n",
    "print(px)\n",
    "print(tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "877e5555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "po = p(px)\n",
    "to = t(tx)\n",
    "print(np.allclose(po[0].numpy(), to.detach().numpy(), atol=1e-5, rtol=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "81428400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(po[0].numpy())\n",
    "# print('')\n",
    "# print(to.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96d7616e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(np.allclose(p.pe, t.pe, atol=1e-4, rtol=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d36882d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 5000, 512]\n",
      "torch.Size([1, 5000, 512])\n",
      "22.627416997969522\n",
      "22.627416997969522\n"
     ]
    }
   ],
   "source": [
    "print(p.pe.shape)\n",
    "print(t.pe.shape)\n",
    "print(p.xscale)\n",
    "print(t.xscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cb53b52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.0000000e+00  1.0000000e+00  0.0000000e+00 ...  1.0000000e+00\n",
      "    0.0000000e+00  1.0000000e+00]\n",
      "  [ 8.4147102e-01  5.4030228e-01  8.2185620e-01 ...  1.0000000e+00\n",
      "    1.0366333e-04  1.0000000e+00]\n",
      "  [ 9.0929741e-01 -4.1614681e-01  9.3641472e-01 ...  1.0000000e+00\n",
      "    2.0732667e-04  1.0000000e+00]\n",
      "  ...\n",
      "  [ 9.5625257e-01 -2.9254240e-01  9.3594456e-01 ...  8.5925674e-01\n",
      "    4.9514842e-01  8.6880839e-01]\n",
      "  [ 2.7049953e-01 -9.6272010e-01  8.2251388e-01 ...  8.5920179e-01\n",
      "    4.9523848e-01  8.6875707e-01]\n",
      "  [-6.6394955e-01 -7.4777740e-01  9.7326015e-04 ...  8.5914677e-01\n",
      "    4.9532855e-01  8.6870575e-01]]]\n"
     ]
    }
   ],
   "source": [
    "print(p.pe.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "557a45a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.00000000e+00  1.00000000e+00  0.00000000e+00 ...  1.00000000e+00\n",
      "    0.00000000e+00  1.00000000e+00]\n",
      "  [ 8.41470957e-01  5.40302336e-01  8.21856201e-01 ...  1.00000000e+00\n",
      "    1.03663326e-04  1.00000000e+00]\n",
      "  [ 9.09297407e-01 -4.16146845e-01  9.36414778e-01 ...  1.00000000e+00\n",
      "    2.07326651e-04  1.00000000e+00]\n",
      "  ...\n",
      "  [ 9.56252575e-01 -2.92542398e-01  9.35944557e-01 ...  8.59256744e-01\n",
      "    4.95148391e-01  8.68808448e-01]\n",
      "  [ 2.70499527e-01 -9.62720096e-01  8.22513878e-01 ...  8.59201729e-01\n",
      "    4.95238483e-01  8.68757069e-01]\n",
      "  [-6.63949549e-01 -7.47777402e-01  1.46154105e-03 ...  8.59146774e-01\n",
      "    4.95328546e-01  8.68705750e-01]]]\n"
     ]
    }
   ],
   "source": [
    "print(t.pe.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712e4390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f2816e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model=512\n",
    "position = torch.arange(0, 5000, dtype=torch.float32).unsqueeze(1)\n",
    "div_term = torch.exp(\n",
    "    torch.arange(0, d_model, 2, dtype=torch.float32)\n",
    "    * -(math.log(10000.0) / d_model)\n",
    "    )\n",
    "p1 = torch.sin(position * div_term)\n",
    "p2 = torch.cos(position * div_term)\n",
    "pe = torch.zeros(5000, d_model)\n",
    "pe[:, 0::2] = p1\n",
    "pe[:, 1::2] = p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "79bab82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "d_model=512\n",
    "nposition = np.arange(0, 5000, dtype=np.float32).reshape(-1, 1)\n",
    "ndiv_term = np.exp(\n",
    "    np.arange(0, d_model, 2, dtype=np.float32)\n",
    "    * -(math.log(10000.0) / d_model)\n",
    "    )\n",
    "np1 = np.sin(nposition * ndiv_term)\n",
    "np2 = np.cos(nposition * ndiv_term)\n",
    "npe = np.zeros((5000, d_model))\n",
    "npe[:, 0::2] = np1\n",
    "npe[:, 1::2] = np2\n",
    "print(type(np1))\n",
    "\n",
    "ppe = paddle.zeros((5000, d_model))\n",
    "ppe[:, 0::2] = paddle.to_tensor(np1)\n",
    "ppe[:, 1::2] = paddle.to_tensor(np2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "70b31bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "---cos/sin\n",
      "False\n",
      "False\n",
      "False\n",
      "---pe\n",
      "False\n",
      "True\n",
      "paddle.float32\n"
     ]
    }
   ],
   "source": [
    "print(np.allclose(nposition, position))\n",
    "print(np.allclose(ndiv_term, div_term))\n",
    "\n",
    "print(\"---cos/sin\")\n",
    "print(np.allclose(np1, p1, atol=1e-5, rtol=0))\n",
    "print(np.allclose(np1, torch.sin(torch.as_tensor(nposition * ndiv_term)), atol=1e-8, rtol=0))\n",
    "print(np.allclose(np2, p2))\n",
    "print('---pe')\n",
    "print(np.allclose(npe, pe))\n",
    "print(np.allclose(npe, ppe))\n",
    "print(ppe.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3b25836c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(p1.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1657d12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
